\chapter{Related Work}\label{chap2}
The sections in this chapter are divided into two, namely, (i) Biomedical Metadata Quality assessments and (ii) Methods that help in identifying biomedical terms in the text -- here we discuss different methods for identifying concepts/terms in the text. 
%\todo{update acc. to hading of paragraph}.

\section{Biomedical metadata quality assessment}
There exist several projects for assessing the quality of biomedical metadata, the methods range from using ontologies, clustering to topic modeling. 
In~\cite{gonccalves2017metadata}, a survey is presented regarding the use of controlled vocabularies when defining metadata categories in BioSamples~\footnote{\url{https://www.ncbi.nlm.nih.gov/biosample/}}. The analysis established that the quality of metadata in BioSamples is poor because of a lack of structured format and vocabularies to describe it. Furthermore, they add that there should be a robust method to enforce authoring of metadata. However, no further analysis was performed regarding improving the quality of existing metadata. 

In~\cite{Hu2017} and~\cite{zaveri2017metacrowd}, gene expression metadata quality assessment was performed on the Gene Omnibus Expression (GEO) database. The assessment was performed using (a) clustering methods and (b) crowdsourcing (i.e. non-expert human workers). In the former, the metadata (keys) were clustered based on (a) lexical similarity, (b) core concepts and (c) value similarities. In the latter empirical analysis was performed on the same set of keys using crowdsourcing by submitting microtasks on the Figure Eight\footnote{\url{https://www.figure-eight.com/}} platform. While both methods were able to classify keys that contained the category term (e.g. `disease state' in the category `disease'), the clustering algorithm misclassified certain keys (e.g. `stage' in the category `age') and there was low consensus amongst workers for key that could belong to more than one category (e.g. `disease specific survival years' that was categorized either into the `disease' or `time' category).

In~\cite{posch2016predicting}, GEO data is used to predict unstructured metadata using the information from the unstructured elements in the metadata. Here the authors employ topic modeling on the unstructured elements of the metadata and use these topics as features to train a supervised classifier namely Support Vector Machines (SVM). Furthermore, a similar classification as written above is performed but in this case, the features were extracted using term frequency-inverse document frequency (TF-IDF). When comparing the results, the feature set using TF-IDF performed better than the features using topic modeling. Although, this method can be useful when predicting structured metadata but it is not very helpful when used over a very large dataset with over $70,000$ features per document.

Similarly in~\cite{panahiazar2017predicting}, prediction of metadata was done using existing metadata, with the help of association rule mining in addition to supervised machine learning. A subset of metadata elements (namely organism and molecule) were selected to perform the predictions. The limitation in this approach was the information gets lost because of arbitrary thresholds of rule mining which further affects the performance of the classification. 

In the work~\cite{panahiazar2015context}, the authors develop a recommendation engine to facilitate the submission of metadata with their use case also being GEO. When users are submitting their metadata, a list of suggestions is generated using context of the information queried. This recommendation also takes into account the previously entered values. These recommendations would reduce the effort of typing when submitting metadata, which would improve the quality of metadata by making it less error-prone, comparable, reusable and interoperable. 

\section{Identifying biomedical terms in text}
Here we discuss different methods that are used in identifying terms in biomedical text and methods which are used to cluster similar terms together. 

\paragraph{Topic Modeling}
In our previous work~\cite{nayak2018quality}, we used topic modeling to identify meaningful topics of the biomedical metadata for BioSamples dataset\footnote{\url{https://www.ebi.ac.uk/biosamples/}}. Can we use topic modeling to identify meaningful topics in biomedical metadata? The metadata in BioSamples is the form of key: value pairs. We applied topic modeling, specifically NMF~\cite{lee1999learning} (non-negative matrix factorization) to the keys and values separately. We divided the keys into two types: (i) lexically similar keys and (ii) non-lexically similar keys. Similarly, we tried to divide the values into two parts: (i) lexically similar values and (ii) non-lexically similar values, but we did not work with the non-lexically similar values because of the heterogeneity present in the values, which made it difficult for the NMF to group topics together in a meaningful way. On the contrary, when working with the keys, the topics were representative of the keys. Although there were limitations to this method as well. The algorithm does not output keywords that are less frequently occurring since it uses TF-IDF to predict the topics. This leads to losing out on important information. We propose to tackle this by adding weights on the less frequently occurring keywords as input. 

\paragraph{Natural Language Processing (NLP)}
In~\cite{chiu2016train}, the authors experiment with different models namely skip gram, Continuous Bag of Words (CBOW)  to create word embedding for Biomedical NLP on the texts of PubMed~\footnote{\url{https://www.ncbi.nlm.nih.gov/pubmed}}, PMC~\footnote{\url{https://www.ncbi.nlm.nih.gov/pmc}}. They also test their model by tuning certain hyperparameters namely negative sampling, subsample rate, min-count, learning rate, vector dimension, context window size the authors use a large input to create word embedding for biomedical NLP. They also mix and match their models with different types of text preprocessing namely normal text, sentence-shuffled text, and lower-case text. They conclude that preprocessing using sentence shuffling for PubMed texts perform better than a larger text corpus of the PubMed Central Open Access subset (PMC). They also conclude that the difference in performance after tuning the hyperparameters can be debated over. 

\paragraph{Named Entity Recognition (NER) and Deep Learning}
In~\cite{habibi2017deep} the authors argue that deep learning with word embeddings would improve the NER in the biomedical domain. They present two methods (i) a traditional method of NER - a basic conditional Random Field (CRF) and (ii) a deep learning network namely called long short-term memory network-conditional random field (LSTM-CRF) and compare the results. They select five different entity classes namely (i) Chemicals, (ii) Genes/Proteins, (iii) Species, (iv) Diseases and (v) Cell lines for their evaluation. They select a set of 24 corpora for these aforementioned five entity types. They use three different word embeddings of Patents, PMC-PubMed and Wiki-PMC-PubMed. These methods perform best with the word embedding of Wiki-PMC-PubMed because it contains information of both domain specific(PMC and PubMed) and general (Wikipedia). Overall it is observed that the deep learning method performs better than the baseline CRF method, which is interesting because the model does not know from before what entity types it is dealing with. 
Lastly, they conclude that for different methods for various entity types can be expensive, which is why a common tool like this should be used for biomedical NER. 

In~\cite{tsui2018creating} the authors use deep learning to create a scalable NER model for text data in the biomedical domain using the entity-free or key-value pairs of the BioSamples dataset. The motivation behind this work was to facilitate information retrieval and extraction. They extract all the metadata from the BioSamples and train a Bidirectional Long Short term Memory (BiLSTM) neural network with the help of word embeddings developed by~\cite{chiu2016train} of Wiki-PMC-Pubmed. They compare their results from existing projects like MetaMap~\footnote{\url{https://metamap.nlm.nih.gov/}}. With the help of word embeddings, they were able to group various types of free-text annotations at word, sentence and entity level. In this approach the author's group the free-text present in the metadata of the dataset. 

\paragraph{Machine Learning}
In one of our previous projects~\cite{nayak2018ML}, we used a machine learning approach to perform an assessment of biomedical metadata. The dataset used was a crowdsourced gold standard set from~\cite{zaveri2017metacrowd}. We used this as a gold standard while performing our experiment. We selected 11 key types as they were top frequently occurring in GEO: (i) tissue, (ii) age, (iii) gender, (iv) strain, (v) cell type, (vi) treatment, (vii) cell line, (viii) sex, (ix) disease, (x) genotype and (xi) time. We used topic modeling to create features and used the scores generated from the topic model as weights. The binary classification approach got the highest accuracy of $0.98$ for the key type `genotype', whereas for a multi-class classification approach we got an accuracy of $0.40$. The limitations of our approach were that it did not support the multi-label classification technique and the size of data was less. \\ 

In this thesis project, the innovative approach is to use scientific biomedical text to predict the metadata which would be a combination of the methods that are described above. 

%In the related work we can see that most of the work is focused on identifying the biomedical concept and not predicting metadata. This supports our hypothesis that using scientific publications to predict metadata would help in improving the quality of biomedical metadata.