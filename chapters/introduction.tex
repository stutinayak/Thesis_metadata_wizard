\chapter{Introduction}\label{chap:intro}

\section{Context and Motivation}

Enormous amounts of biomedical data have been and are being produced at an unprecedented rate by researchers all over the world~\cite{hoffman2013use}. 
This is mainly due to advancements in molecular technologies that have enabled extensive profiling of biological samples and have unleashed a myriad of so-called \emph{`omics} data such as gene expression, microRNA expression, DNA methylation, and DNA mutation data. 
During the last decade or so journals, investigators, funding agencies have realized that this data should be stored, shared with and used by other investigators.
However, to enable reuse there is an urgent need to understand the structure of datasets and the experimental conditions under which they were produced~\cite{borgman2012conundrum}.
That is, there is an urgent need for accurate, structured and complete description of the data -- defined as \emph{metadata}.

While there exists an abundance of open biomedical data, the lack of high quality metadata makes it challenging for others to find relevant datasets and to reuse them for another purpose~\cite{gonccalves2017metadata, Hu2017}. 
This, in turn, can facilitate a data-driven approach by combining and analyzing similar data to uncover novel insights or even more subtle trends in the data.
These insights can then be formed into a hypothesis that can be tested in the laboratory~\cite{barrett2012ncbi}.
In particular, metadata are useful to understand the nature and provenance of the data. A common approach to improving the quality of metadata relies on expensive human curation, which itself is time consuming and also prone to error.
Poor metadata leads to the problems of (i) interpretability - can we understand what was done in the biomedical experiment? and (ii) improved precision and recall in database queries - to find all studies that meet constraints (e.g. all studies for a particular disease) and (iii) re-usability - to use this data for discovery, validation, and reproducibility.

The recently published FAIR principles specify desirable criteria that metadata and their corresponding datasets should meet to be Findable, Accessible, Interoperable, and Reusable~\cite{Wilkinson2016}.
For data to be FAIR, metadata needs to be accurate and uniform (relying on controlled terms where possible). However, currently there is a large amount of biomedical metadata, which is of poor quality, that is, it is extremely heterogeneous and which makes data re-use extremely difficult~\cite{gonccalves2017metadata}. 
Although there has been a lot of work done in meta-analysis of public omics data. One particular example demonstrated by Khatri and colleagues~\cite{khatri2013common}, depicts the power of integrating data from publicly available sources where investigators had used different assay technologies, resulting in the identification of a common mechanism of transplant rejection using only publicly available gene-expression data. 
They then showed that the gene signatures associated with this mechanism improved diagnosis, and ultimately led to the identification of two drugs previously approved by the FDA that can be repurposed to treat transplant rejection,
For Khatri and colleagues, a key impediment to their success was the low quality of the metadata associated with gene expression datasets. Their work required them to tediously examine and curate each and every dataset and associated publication to create metadata pertaining to the organism, tissue, protocol, and other essential parameters, so that they could use datasets that specifically met their inclusion criteria.

 One of the major challenge towards assessing and improving the quality of biomedical metadata is the size of data that is present.  Delving further into the problem at hand -- let's take an example of Gene Expression Omnibus (GEO) dataset~\cite{edgar2002gene} which is a widely used database for cross-species gene expression data. Currently users can submit data to GEO via three ways: (i) Spreadsheets, (ii) SOFT format (plain text), (iii) MINiML format\footnote{`MIAME Notation in Markup Language' format} (XML).
When users submit data to GEO via a spreadsheet, it requires them to fill out a metadata template that follows the guidelines set out by the Minimum Information About a Microarray Experiment (MIAME) guidelines~\cite{brazma2001minimum}. GEO allows users to specify metadata in the form of textual key: value pairs (e.g. \emph{sex: female}). However, since there is no structured vocabulary or format available, the 44,000,000+ \emph{key: value} pairs suffer from numerous quality issues such as:
\begin{itemize}
\item minor spelling discrepancies\\ (e.g. \verb|age at diagnosis (years)|, \verb|age at diagonosis (years)|; 
\verb|genotype/varat,|\\ \verb|genotype/varaiation, genotype/variaion| \verb|genotype/variataion|)
\item having different syntactic representations (e.g. \verb|age (years), age(yrs)|\\ \verb|and age_year|)
\item using different terms altogether to denote one concept (e.g. \verb|disease| vs. \verb|illness| vs. \verb|condition|)
\item using two different key terms in one (e.g. \verb|disease/cell type|, \verb|tissue/cell line|, \verb|treatment age|).
\end{itemize} 
Looking at these issues it can be seen that there is an urgent need to solve this research problem which would in-turn facilitate the re-usability of data. 

\section{Research Questions and Outline}

Using domain experts for the curation of assessing the quality of metadata is not only time consuming, but also not scalable. 
Moreover, without a standardized set of terms with which to fill out the template fields (in the form when filling out the metadata), there are different versions of the same term without any (semantic) links between them, thus leading to several quality problems. Thus, there is a need for efficient methods for curating the metadata. In our previous projects~\cite{nayak2018quality, nayak2018ML} we tried to cluster similar terms together using topic modeling and machine learning respectively. But when dealing with the values it is very complex to map them to a concept because of a large amount of data. Whereas in scientific publication, we can identify values and then map them to a respective concept, this can be done per document. Therefore, we could exploit the information present in the scientific publication - where our aim is to automatically predict metadata from scientific publications (unstructured text) using Machine Learning or Deep Learning in other words we want to build a \textbf{Metadata Wizard}.

We hypothesize that the scientific publications have in-depth descriptions of the experiments performed which facilitate predicting better quality metadata. 
The research questions outlined for this project are listed below:
\begin{itemize}
    \item RQ1: To what extent can we \textbf{automatically} predict metadata (key-value pairs) describing experiments from scientific publications?%\todo{be specific keys or values?}
    \item RQ2: Which specific metadata keys can be accurately predicted?
    \item RQ3: What set of features contribute to the accurate prediction of metadata?
    \item RQ4: Which is the best automated (machine learning/deep learning) method to predict metadata?
    \item RQ5: To what extent does the accuracy improves when we use abstract and full text?
\end{itemize}

\paragraph{Contributions} 
The contributions in this thesis project are to develop a Wizard which tells the metadata when given an unstructured text:
\begin{itemize}
\item  developed a model for identifying metadata using scientific publications focusing on the metadata category \emph{disease}, 
\item performed empirical experiments on NCBI disease corpus~\cite{dougan2014ncbi} to identify disease categories and specific disease using different neural network approach and \item performed in-depth analysis of results. 
\end{itemize}

\paragraph{Outline}
The thesis is structured as follows, Chapter~\ref{chap:intro} introduces the problem statement, motivation and research question that the project aims to answer. Chapter~\ref{chap2} reports about the related work that has been done in this area of research and a brief mention of how this thesis project is different with all that work that has already been done mentioning the innovation of this approach. Chapter~\ref{chap:method} describes the method that has been performed including explanations about the terminologies used. In Chapter~\ref{chap:nnmethod} we describe the model specification in the context of Natural language processing (NLP). Chapter~\ref{chap: results} discusses the results and the analysis of those results. 
%The chapter~\ref{chap:eval} discusses an evaluation of results using a baseline, basic method.
Lastly, chapter~\ref{conclusion chapter} discusses a brief summary, conclusions drawn, the limitations and the future work of the project. 